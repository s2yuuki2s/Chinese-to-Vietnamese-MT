{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b34859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sacrebleu.metrics import BLEU\n",
    "from bert_score import score\n",
    "from googletrans import Translator\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc929e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SRC = 'PDF1'\n",
    "FROM_ID = 501\n",
    "TO_ID = 625\n",
    "INPUT_FILE = f\"../output/alignment/{SRC}_{FROM_ID}_{TO_ID}.csv\" \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d2acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxy_translations(df, sample_size):\n",
    "    \"\"\"\n",
    "    Dịch câu nguồn tiếng Trung sang tiếng Việt dùng Google Translate\n",
    "    để làm tham chiếu so sánh.\n",
    "    \"\"\"\n",
    "    print(f\"Đang lấy mẫu ngẫu nhiên {sample_size} cặp câu để đánh giá...\")\n",
    "    \n",
    "    # Lấy mẫu ngẫu nhiên\n",
    "    sample = df.sample(n=min(sample_size, len(df)), random_state=0).copy()\n",
    "\n",
    "    translator = Translator()\n",
    "    hypotheses = [] # Câu trong file \n",
    "    references = [] # Câu dịch máy (Làm chuẩn so sánh)\n",
    "    success_count = 0\n",
    "    \n",
    "    for idx, row in tqdm(sample.iterrows(), total=len(sample)):\n",
    "        src = str(row['src_lang'])\n",
    "        tgt = str(row['tgt_lang']) # Đây là câu tiếng Việt gốc trong dataset\n",
    "        \n",
    "        # Bỏ qua câu quá ngắn hoặc rỗng\n",
    "        if len(src) < 2 or len(tgt) < 5: \n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Dịch Trung -> Việt\n",
    "            translated = translator.translate(src, src='zh-cn', dest='vi').text\n",
    "            \n",
    "            # Câu Google dịch là Reference (Tham chiếu) và câu Tgt gốc là Hypothesis (Giả thuyết)\n",
    "            references.append(translated) \n",
    "            hypotheses.append(tgt)\n",
    "            \n",
    "            success_count += 1\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Nếu lỗi mạng thì bỏ qua\n",
    "            continue\n",
    "            \n",
    "    print(f\"Đã dịch thành công {success_count} câu.\")\n",
    "    return hypotheses, references\n",
    "\n",
    "def calculate_metrics(hypotheses, references):\n",
    "    \"\"\"Tính toán BLEU và BERTScore\"\"\"\n",
    "    if not hypotheses:\n",
    "        print(\"Không có dữ liệu để tính toán.\")\n",
    "        return\n",
    "\n",
    "    # Tính BLEU Score\n",
    "    # BLEU đánh giá độ khớp từ vựng (n-gram overlap)\n",
    "    bleu = BLEU()\n",
    "    bleu_score = bleu.corpus_score(hypotheses, [references])\n",
    "    \n",
    "    print(f\"BLEU Score: {bleu_score.score:.2f}\")\n",
    "\n",
    "    # Tính BERTScore\n",
    "    # BERTScore đánh giá độ tương đồng ngữ nghĩa (Semantic Similarity) dùng mô hình BERT\n",
    "    P, R, F1 = score(hypotheses, references, lang='vi', verbose=False, device=DEVICE)\n",
    "    \n",
    "    avg_bert = F1.mean().item()\n",
    "    print(f\"BERTScore (F1): {avg_bert:.4f}\")\n",
    "\n",
    "    print(\"Ví dụ tham chiếu (Top 3):\")\n",
    "    for i in range(min(3, len(hypotheses))):\n",
    "        print(f\"Cặp {i+1}:\")\n",
    "        print(f\"Dataset Tgt: {hypotheses[i]}\")\n",
    "        print(f\"Google Trans: {references[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c147ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang lấy mẫu ngẫu nhiên 149 cặp câu để đánh giá...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [04:48<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã dịch thành công 149 câu.\n",
      "BLEU Score: 45.98\n",
      "BERTScore (F1): 0.9033\n",
      "Ví dụ tham chiếu (Top 3):\n",
      "Cặp 1:\n",
      "Dataset Tgt: Bằng cách sử dụng công cụ đường dẫn nhân quả của họ, chúng tôi đã có thể xác định các đường dẫn bị ảnh hưởng khác biệt nhất, không chỉ các protein riêng lẻ từ bản đồ nhiệt đó.\n",
      "Google Trans: Bằng cách sử dụng công cụ lộ trình nhân quả của họ, chúng tôi có thể xác định những con đường bị ảnh hưởng nhiều nhất, không chỉ các protein riêng lẻ trong bản đồ nhiệt.\n",
      "Cặp 2:\n",
      "Dataset Tgt: và nói rằng, tốt, chúng tôi có hai tin tốt cho bạn.\n",
      "Google Trans: Và nói rằng, chúng tôi có hai tin tốt cho bạn.\n",
      "Cặp 3:\n",
      "Dataset Tgt: Liều lượng cho một người 18 tuổi.\n",
      "Google Trans: Liều dùng cho trẻ 18 tuổi.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_FILE)\n",
    "# Thực hiện quy trình đánh giá\n",
    "SAMPLE_SIZE = int(df.shape[0] * 0.1)  # Số lượng câu lấy mẫu để đánh giá \n",
    "hyps, refs = get_proxy_translations(df, SAMPLE_SIZE)\n",
    "# Tính điểm\n",
    "calculate_metrics(hyps, refs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
