{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "aaa5435a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Data\\HCMUS\\Y4\\Y4_S1\\Nhap_mon_xu_ly_ngon_ngu_tu_nhien\\Mid_term\\venv\\Lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
            "  warnings.warn(warning_message)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "from collections import defaultdict\n",
        "import difflib\n",
        "import pandas as pd\n",
        "from paddleocr import PaddleOCR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bc162631",
      "metadata": {},
      "outputs": [],
      "source": [
        "ocr = PaddleOCR(\n",
        "    use_angle_cls=True,\n",
        "    lang='ch',\n",
        "    show_log=False,\n",
        "    use_gpu=True,\n",
        "    gpu_id=0,\n",
        "    gpu_mem=4096\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d60d5dec",
      "metadata": {},
      "outputs": [],
      "source": [
        "def strip_accents(s: str) -> str:\n",
        "    # Loại bỏ dấu \n",
        "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
        "\n",
        "def is_chinese(text: str) -> bool:\n",
        "    return any('\\u4e00' <= ch <= '\\u9fff' for ch in text)\n",
        "\n",
        "def is_page_number_line(text: str) -> bool:\n",
        "    return re.fullmatch(r\"\\d{1,4}\", text.strip()) is not None\n",
        "\n",
        "# Kiểm tra dòng chữ \"Bức thư...\" để xác định vùng tiếng Việt\n",
        "def looks_like_vietnamese(text: str) -> bool:\n",
        "    norm = strip_accents(text).lower()\n",
        "    tokens = re.findall(r\"[a-z0-9]+\", norm)\n",
        "\n",
        "    def has_similar(target: str, thr: float) -> bool:\n",
        "        for t in tokens:\n",
        "            if difflib.SequenceMatcher(None, t, target).ratio() >= thr:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    req_ok = (\n",
        "        has_similar(\"buc\", 0.5) and\n",
        "        has_similar(\"thu\", 0.5) and\n",
        "        has_similar(\"viet\", 0.5) and\n",
        "        has_similar(\"cho\", 0.5) and\n",
        "        has_similar(\"chinh\", 0.5) and\n",
        "        has_similar(\"minh\", 0.5)\n",
        "    )\n",
        "\n",
        "    return req_ok\n",
        "\n",
        "# Trích xuất ID của bức thư\n",
        "def extract_id(text: str):\n",
        "    def norm_digits(tok: str):\n",
        "        tok = tok.strip()\n",
        "        tok = tok.replace('O', '0').replace('o', '0')\n",
        "        tok = tok.replace('I', '1').replace('l', '1').replace('|', '1').replace('!', '1')\n",
        "\n",
        "        digits = \"\".join(re.findall(r\"\\d+\", tok))  # \"50 4\" -> \"504\"\n",
        "        if not digits:\n",
        "            return None\n",
        "        if len(digits) < 3:\n",
        "            return None\n",
        "        return digits\n",
        "\n",
        "    # Chinese: 第xxx \n",
        "    m = re.search(r\"第\\s*([0-9OoIl|!\\s]{1,20})\", text)\n",
        "    if m:\n",
        "        return norm_digits(m.group(1))\n",
        "\n",
        "    # Vietnamese: so/s0/s6 ...\n",
        "    norm = strip_accents(text).lower()\n",
        "    m = re.search(r\"(?:\\bso\\b|\\bs0\\b|\\bs6\\b|s[0o6])\\s*([0-9OoIl|!\\s]{1,20})\", norm)\n",
        "    if m:\n",
        "        return norm_digits(m.group(1))\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "76b1c3df",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_MAP = defaultdict(lambda: {\"src\": [], \"tgt\": [], \"vi_started\": False})\n",
        "STATE = {\"current_id\": None, \"mode\": None, \"pending_src\": []}\n",
        "\n",
        "# OCR\n",
        "def process_image_to_data(img_path: str, data_map=DATA_MAP, state=STATE):\n",
        "    print(f\"Đang xử lý: {img_path}...\")\n",
        "    result = ocr.ocr(img_path, cls=True)\n",
        "    if not result or result[0] is None:\n",
        "        return\n",
        "\n",
        "    blocks = result[0]\n",
        "    blocks = sorted(\n",
        "        blocks,\n",
        "        key=lambda b: (min(p[1] for p in b[0]), min(p[0] for p in b[0]))\n",
        "    )\n",
        "    lines = [b[1][0].strip() for b in blocks if b and b[1] and b[1][0]]\n",
        "\n",
        "    current_id = state[\"current_id\"]\n",
        "    mode = state[\"mode\"]\n",
        "    pending_src = state[\"pending_src\"]\n",
        "\n",
        "    for text in lines:\n",
        "        if not text:\n",
        "            continue\n",
        "        if is_page_number_line(text):\n",
        "            continue\n",
        "        \n",
        "        # Title tiếng Việt (fuzzy) -> mode=vi (lấy ID) và chỉ xử lý như title nếu extract được ID\n",
        "        if looks_like_vietnamese(text):\n",
        "            maybe_id = extract_id(text)\n",
        "            if maybe_id:\n",
        "                # Title thật\n",
        "                current_id = maybe_id\n",
        "                _ = data_map[current_id]\n",
        "                if pending_src:\n",
        "                    data_map[current_id][\"src\"].extend(pending_src)\n",
        "                    pending_src.clear()\n",
        "\n",
        "                mode = \"vi\"\n",
        "                if not data_map[current_id][\"vi_started\"]:\n",
        "                    data_map[current_id][\"tgt\"] = []\n",
        "                    data_map[current_id][\"vi_started\"] = True\n",
        "                continue\n",
        "\n",
        "        # Anchor ID (ưu tiên từ tiếng Trung: 第...)\n",
        "        found_id = extract_id(text)\n",
        "        if found_id:\n",
        "            current_id = found_id\n",
        "            _ = data_map[current_id]\n",
        "            if pending_src:\n",
        "                data_map[current_id][\"src\"].extend(pending_src)\n",
        "                pending_src.clear()\n",
        "\n",
        "            mode = \"zh\" if is_chinese(text) else \"vi\"\n",
        "            if mode == \"vi\" and (not data_map[current_id][\"vi_started\"]):\n",
        "                data_map[current_id][\"tgt\"] = []\n",
        "                data_map[current_id][\"vi_started\"] = True\n",
        "            continue\n",
        "\n",
        "        # Chưa có ID -> giữ tiếng Trung để chờ, bỏ qua Pinyin\n",
        "        if current_id is None:\n",
        "            if is_chinese(text):\n",
        "                pending_src.append(text)\n",
        "            continue\n",
        "\n",
        "        # Gom nội dung theo mode\n",
        "        if is_chinese(text):\n",
        "            if mode == \"vi\":\n",
        "                # Gặp tiếng Trung sau tiếng Việt -> Reset để chờ ID mới\n",
        "                pending_src.append(text)\n",
        "                current_id = None\n",
        "                mode = \"zh\"\n",
        "            else:\n",
        "                data_map[current_id][\"src\"].append(text)\n",
        "        else:\n",
        "            if mode == \"vi\":\n",
        "                data_map[current_id][\"tgt\"].append(text)\n",
        "\n",
        "    state[\"current_id\"] = current_id\n",
        "    state[\"mode\"] = mode\n",
        "    state[\"pending_src\"] = pending_src\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9d547504",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang xử lý: ../data/image/PDF1\\PDF1-203.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-204.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-205.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-206.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-207.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-208.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-209.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-210.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-211.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-212.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-213.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-214.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-215.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-216.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-217.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-218.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-219.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-220.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-221.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-222.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-223.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-224.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-225.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-226.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-227.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-228.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-229.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-230.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-231.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-232.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-233.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-234.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-235.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-236.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-237.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-238.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-239.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-240.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-241.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-242.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-243.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-244.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-245.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-246.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-247.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-248.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-249.png...\n",
            "Đang xử lý: ../data/image/PDF1\\PDF1-250.png...\n",
            "Saved: ../data/preprocessing_data\\PDF1_500_627.csv\n"
          ]
        }
      ],
      "source": [
        "IMG_DIR = \"../data/image/PDF1\"\n",
        "START_PAGE = 203\n",
        "END_PAGE = 250\n",
        "OUT_DIR = \"../data/preprocessing_data\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "for p in range(START_PAGE, END_PAGE + 1):\n",
        "    img_path = os.path.join(IMG_DIR, f\"PDF1-{p}.png\")\n",
        "    if os.path.exists(img_path):\n",
        "        process_image_to_data(img_path, DATA_MAP, STATE)\n",
        "\n",
        "# Join thành df \n",
        "rows = []\n",
        "for sid, v in DATA_MAP.items():\n",
        "    src_text = \" \".join(v[\"src\"]).strip()\n",
        "    tgt_text = \" \".join(v[\"tgt\"]).strip()\n",
        "    if src_text or tgt_text:\n",
        "        rows.append({\"src_id\": sid, \"src_lang\": src_text, \"tgt_lang\": tgt_text})\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"src_id\", \"src_lang\", \"tgt_lang\"])\n",
        "if not df.empty:\n",
        "    df[\"src_id_int\"] = df[\"src_id\"].astype(int)\n",
        "    df = df.sort_values(\"src_id_int\").drop(columns=[\"src_id_int\"]).reset_index(drop=True)\n",
        "\n",
        "min_id = int(df[\"src_id\"].astype(int).min()) if not df.empty else 0\n",
        "max_id = int(df[\"src_id\"].astype(int).max()) if not df.empty else 0\n",
        "out_csv = os.path.join(OUT_DIR, f\"PDF1_{min_id}_{max_id}.csv\")\n",
        "df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"Saved:\", out_csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c714e56d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src_id</th>\n",
              "      <th>src_lang</th>\n",
              "      <th>tgt_lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "      <td></td>\n",
              "      <td>yu ' y en q o nu d nu n    nu xem lai xem minh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>501</td>\n",
              "      <td>懂得让步的人是聪明的，这是把决定事态走向的主动权握在了自己手 上。感情对抗战中，赢了面子就输...</td>\n",
              "      <td>Nguoi thong minh la nguoi biet lui buoc, dieu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>说到底，女人还是要自强：不容易生病的身体、够用的收入、养心的 爱好、强大的小宇宙。拥有这些不...</td>\n",
              "      <td>Suy cho cung, phu nu van can tu lap, can co su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>503</td>\n",
              "      <td>感情就是这样，没有失去你不会成熟，生活也是这样，没有遇到点险 恶，你不会长大。你想要的，老天...</td>\n",
              "      <td>Tinh cam la nhu vay d6, khong danh mat thi kho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>504</td>\n",
              "      <td>能打动我的从来不是花言巧语，而是恰到好处的温柔以及真挚的内心。</td>\n",
              "      <td>Thur thyrc su lay dong trai tim em khong phai ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  src_id                                           src_lang  \\\n",
              "0    500                                                      \n",
              "1    501  懂得让步的人是聪明的，这是把决定事态走向的主动权握在了自己手 上。感情对抗战中，赢了面子就输...   \n",
              "2    502  说到底，女人还是要自强：不容易生病的身体、够用的收入、养心的 爱好、强大的小宇宙。拥有这些不...   \n",
              "3    503  感情就是这样，没有失去你不会成熟，生活也是这样，没有遇到点险 恶，你不会长大。你想要的，老天...   \n",
              "4    504                    能打动我的从来不是花言巧语，而是恰到好处的温柔以及真挚的内心。   \n",
              "\n",
              "                                            tgt_lang  \n",
              "0  yu ' y en q o nu d nu n    nu xem lai xem minh...  \n",
              "1  Nguoi thong minh la nguoi biet lui buoc, dieu ...  \n",
              "2  Suy cho cung, phu nu van can tu lap, can co su...  \n",
              "3  Tinh cam la nhu vay d6, khong danh mat thi kho...  \n",
              "4  Thur thyrc su lay dong trai tim em khong phai ...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
